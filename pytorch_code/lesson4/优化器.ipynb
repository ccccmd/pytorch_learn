{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pytorch的优化器：管理并更新模型中可学习参数的值，使得模型输出更接近真实标签  \n",
    "导数：函数在指定坐标轴上的变化率  \n",
    "梯度：一个向量，方向为方向导数取得最大值的方向  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本属性  \n",
    "* defaults:优化器超参数  \n",
    "* state:参数的缓存，如momentum的缓存  \n",
    "* param_groups:管理的参数组  \n",
    "* _step_count:记录更新次数，学习率调整中使用  \n",
    "\n",
    "基本方法：  \n",
    "* zero_grad():清空所管理参数的梯度  \n",
    "pytorch:张量梯度不自动清零  \n",
    "* step():执行一步更新  \n",
    "* add_param_group():添加参数组  \n",
    "* state_dict():获取优化器当前状态信息字典  \n",
    "* load_state_dict():加载状态信息字典#保存当前状态信息，防止因为意外避免模型终止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "weight = torch.randn((2, 2), requires_grad=True)\n",
    "weight.grad = torch.ones((2, 2))\n",
    "optimizer = optim.SGD([weight], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9556, -0.0451],\n        [-0.4985,  0.6649]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "weight.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0556, -0.1451],\n        [-0.5985,  0.5649]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.step()\n",
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0556, -0.1451],\n        [-0.5985,  0.5649]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zero_grad\n",
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1556, -0.2451],\n         [-0.6985,  0.4649]]),\n 4758795120,\n 4758795120)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.step()\n",
    "weight.data, id(optimizer.param_groups[0]['params'][0]), id(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n        [1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n        [0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([[-1.1556, -0.2451],\n           [-0.6985,  0.4649]], requires_grad=True)],\n  'lr': 0.1,\n  'momentum': 0,\n  'dampening': 0,\n  'weight_decay': 0,\n  'nesterov': False}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add_param_group\n",
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [tensor([[-1.1556, -0.2451],\n           [-0.6985,  0.4649]], requires_grad=True)],\n  'lr': 0.1,\n  'momentum': 0,\n  'dampening': 0,\n  'weight_decay': 0,\n  'nesterov': False},\n {'params': [tensor([[ 0.3344, -0.1886, -0.2457],\n           [ 1.4255,  0.6913, -0.3347],\n           [ 1.0530,  0.7267, -1.8213]], requires_grad=True)],\n  'lr': 0.0001,\n  'momentum': 0,\n  'dampening': 0,\n  'weight_decay': 0,\n  'nesterov': False}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = torch.randn((3, 3), requires_grad=True)\n",
    "optimizer.add_param_group({\"params\": w2, 'lr': 0.0001})\n",
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n 'param_groups': [{'lr': 0.1,\n   'momentum': 0.9,\n   'dampening': 0,\n   'weight_decay': 0,\n   'nesterov': False,\n   'params': [4758795120]}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#state_dict\n",
    "optimizer = optim.SGD([weight], lr=0.1, momentum=0.9)\n",
    "opt_state_dict = optimizer.state_dict()\n",
    "opt_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {4758795120: {'momentum_buffer': tensor([[0., 0.],\n           [0., 0.]])}},\n 'param_groups': [{'lr': 0.1,\n   'momentum': 0.9,\n   'dampening': 0,\n   'weight_decay': 0,\n   'nesterov': False,\n   'params': [4758795120]}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    optimizer.step()\n",
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), os.path.join(\"optimizer_state_dict.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n 'param_groups': [{'lr': 0.1,\n   'momentum': 0.9,\n   'dampening': 0,\n   'weight_decay': 0,\n   'nesterov': False,\n   'params': [4758795120]}]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load state_dict\n",
    "optimizer = optim.SGD([weight], lr=0.1, momentum=0.9)\n",
    "state_dict = torch.load(os.path.join(\"optimizer_state_dict.pkl\"))\n",
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {4758795120: {'momentum_buffer': tensor([[0., 0.],\n           [0., 0.]])}},\n 'param_groups': [{'lr': 0.1,\n   'momentum': 0.9,\n   'dampening': 0,\n   'weight_decay': 0,\n   'nesterov': False,\n   'params': [4758795120]}]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.load_state_dict(state_dict)\n",
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用学习率控制更新的步伐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10ce9b990>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x_t):\n",
    "    return torch.pow(2 * x_t, 2)\n",
    "x = torch.tensor([2.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data\n",
    "x_t = torch.linspace(-3, 3, 100)\n",
    "y = func(x_t)\n",
    "plt.plot(x_t.numpy(), y.numpy(), label='y = 4 * x ^ 2')\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:0, X:     2.0, X.grad:    16.0, loss:      16.0\nIter:1, X:1.840000033378601, X.grad:14.720000267028809, loss:13.542400360107422\nIter:2, X:1.6928000450134277, X.grad:13.542400360107422, loss:11.462287902832031\nIter:3, X:1.5573760271072388, X.grad:12.45900821685791, loss:9.701680183410645\nIter:4, X:1.432785987854004, X.grad:11.462287902832031, loss:8.211503028869629\nIter:5, X:1.3181631565093994, X.grad:10.545305252075195, loss:6.950216293334961\nIter:6, X:1.2127101421356201, X.grad:9.701681137084961, loss:5.882663726806641\nIter:7, X:1.1156933307647705, X.grad:8.925546646118164, loss:4.979086399078369\nIter:8, X:1.0264378786087036, X.grad:8.211503028869629, loss:4.214298725128174\nIter:9, X:0.9443228244781494, X.grad:7.554582595825195, loss:3.5669822692871094\nIter:10, X:0.8687769770622253, X.grad:6.950215816497803, loss:3.0190937519073486\nIter:11, X:0.7992748022079468, X.grad:6.394198417663574, loss:2.555360794067383\nIter:12, X:0.7353328466415405, X.grad:5.882662773132324, loss:2.1628575325012207\nIter:13, X:0.6765062212944031, X.grad:5.412049770355225, loss:1.8306427001953125\nIter:14, X:0.6223857402801514, X.grad:4.979085922241211, loss:1.549456000328064\nIter:15, X:0.5725948810577393, X.grad:4.580759048461914, loss:1.3114595413208008\nIter:16, X:0.526787281036377, X.grad:4.214298248291016, loss:1.110019326210022\nIter:17, X:0.4846442937850952, X.grad:3.8771543502807617, loss:0.9395203590393066\nIter:18, X:0.4458727538585663, X.grad:3.5669820308685303, loss:0.795210063457489\nIter:19, X:0.41020292043685913, X.grad:3.281623363494873, loss:0.673065721988678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenmengda/opt/anaconda3/envs/pytorch_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "iter_rec, loss_rec, x_rec = list(), list(), list()\n",
    "lr = 0.01\n",
    "max_iteration = 20\n",
    "for i in range(max_iteration):\n",
    "    y = func(x)\n",
    "    y.backward()\n",
    "    print(\"Iter:{}, X:{:8}, X.grad:{:8}, loss:{:10}\".format(i, x.detach().numpy()[0], x.grad.detach().numpy()[0], y.item()))\n",
    "    x_rec.append(x.item())\n",
    "    x.data.sub_(lr * x.grad)\n",
    "    x.grad.zero_()\n",
    "    iter_rec.append(i)\n",
    "    loss_rec.append(y)\n",
    "plt.subplot(121).plot(iter_rec, loss_rec, '-ro')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss value\")\n",
    "x_t = torch.linspace(-3, 3, 100)\n",
    "y = func(x_t)\n",
    "plt.subplot(122).plot(x_t.numpy(), y.numpy(), label=\"y = 4 * x ^ 2\")\n",
    "plt.grid()\n",
    "y_rec = [func(torch.tensor(i)).item() for i in x_rec]\n",
    "plt.subplot(122).plot(x_rec, y_rec, '-ro')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi learning rate\n",
    "iteration = 100\n",
    "num_lr = 10\n",
    "lr_min, lr_max = 0.01, 0.2\n",
    "lr_list = np.linspace(lr_min, lr_max, num=num_lr).tolist()\n",
    "loss_rec = [[] for l in range(len(lr_list))]\n",
    "iter_rec = list()\n",
    "for i, lr in enumerate(lr_list):\n",
    "    x = torch.tensor([2.], requires_grad=True)\n",
    "    for iter in range(iteration):\n",
    "        y = func(x)\n",
    "        y.backward()\n",
    "        x.data.sub_(lr * x.grad)\n",
    "        x.grad.zero_()\n",
    "        loss_rec[i].append(y.item())\n",
    "for i, loss_r in enumerate(loss_rec):\n",
    "    plt.plot(range(len(loss_r)), loss_r, label=\"LR: {}\".format(lr_list[i]))\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用学习率控制更新的步伐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum（动量，冲量）：结合当前梯度与上一次更新信息，用于当前更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_w_func(beta, time_list):\n",
    "    return [(1 - beta) * np.power(beta, exp) for exp in time_list]\n",
    "beta = 0.9\n",
    "num_point = 100\n",
    "time_list = np.arange(num_point).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999734386011124"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = exp_w_func(beta, time_list)\n",
    "plt.plot(time_list, weights, '-ro', label=\"Beta: {}\\n y = B^t * (1-B)\".format(beta))\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"weight\")\n",
    "plt.legend()\n",
    "plt.title(\"exponentially weighted average\")\n",
    "plt.show()\n",
    "np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi weights\n",
    "beta_list = [0.98, 0.95, 0.9, 0.8]\n",
    "w_list = [exp_w_func(beta, time_list) for beta in beta_list]\n",
    "for i, w in enumerate(w_list):\n",
    "    plt.plot(time_list, w, label='Beta:{}'.format(beta_list[i]))\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel(\"weight\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD momentum\n",
    "def func(x):\n",
    "    return torch.pow(2 * x, 2)\n",
    "iteration = 100\n",
    "m = 0.9\n",
    "lr_list = [0.01, 0.03]\n",
    "momentum_list = list()\n",
    "loss_rec = [[] for l in range(len(lr_list))]\n",
    "iter_rec = list()\n",
    "for i, lr in enumerate(lr_list):\n",
    "    x = torch.tensor([2.], requires_grad=True)\n",
    "    momentum = 0. if lr == 0.03 else m\n",
    "    momentum_list.append(momentum)\n",
    "    optimizer = optim.SGD([x], lr = lr, momentum = momentum)\n",
    "    for iter in range(iteration):\n",
    "        y = func(x)\n",
    "        y.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_rec[i].append(y.item())\n",
    "for i, loss_r in enumerate(loss_rec):\n",
    "    plt.plot(range(len(loss_r)), loss_r, label='LR:{} M:{}'.format(lr_list[i], momentum_list[i]))\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optim.SGD  \n",
    "主要参数：\n",
    "* params:管理的参数组  \n",
    "* lr:初始学习率  \n",
    "* momentum:动量系数，ß  \n",
    "* weight_decay:L2正则化系数  \n",
    "* nesterov:是否采用NAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
