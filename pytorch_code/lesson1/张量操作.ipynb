{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "张量操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量拼接与切分  \n",
    "torch.cat()  \n",
    "功能： 将张量按维度dim进行拼接  \n",
    "* tensors:张量序列  \n",
    "* dim:要拼接的维度  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x114e7c9b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]]),\n tensor([[1., 1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones((2, 3))\n",
    "t_0 = torch.cat([t, t], dim=0)\n",
    "t_1 = torch.cat([t, t], dim=1)\n",
    "t_0, t_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.stack()  \n",
    "功能：在新创建的维度dim上进行拼接  \n",
    "* tensors:张量序列  \n",
    "* dim:要拼接的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1.],\n          [1., 1., 1.]],\n \n         [[1., 1., 1.],\n          [1., 1., 1.]],\n \n         [[1., 1., 1.],\n          [1., 1., 1.]]]),\n torch.Size([3, 2, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones((2, 3))\n",
    "t_stack = torch.stack([t, t, t], dim=0)\n",
    "t_stack, t_stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.chunk()  \n",
    "功能：将张量按维度dim进行平均切分  \n",
    "返回值：张量列表  \n",
    "注意事项：若不能整除，最后一份张量小于其他张量  \n",
    "* input:要切分的张量  \n",
    "* chunks:要切分的份数  \n",
    "* dim:要切分的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 8])\ntorch.Size([2, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2,4,8))\n",
    "t_chunk = torch.chunk(a, chunks=2, dim=1)\n",
    "for idx, t in enumerate(t_chunk):\n",
    "    print(t.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.split()  \n",
    "功能：将张量按维度dim进行切分  \n",
    "返回值：张量列表  \n",
    "* tensor:要切分的张量  \n",
    "* split_size_or_sections:为int时，表示每一份的长度；为list时，按list元素切分  \n",
    "* dim:要切分的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\ntorch.Size([2, 1])\ntorch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 5))\n",
    "t_split = torch.split(a, [1,1,3], dim=1)\n",
    "for idx, t in enumerate(t_split):\n",
    "    print(t.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.index_select()  \n",
    "功能：在维度dim上，按index索引数据  \n",
    "返回值：依index索引数据拼接的张量  \n",
    "* input:要索引的张量  \n",
    "* dim:要索引的维度  \n",
    "* index:要索引数据的序号  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 5, 0],\n         [5, 7, 1],\n         [2, 5, 8]]),\n tensor([[4, 5, 0],\n         [2, 5, 8]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randint(0, 9, size=(3, 3))#必须为torch.long\n",
    "t_select = torch.index_select(t, dim=0, index=idx)\n",
    "t,t_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.masked_select()  \n",
    "功能：按mask中的True进行索引  \n",
    "返回值：一维张量  \n",
    "* input:要索引的张量  \n",
    "* mask:与input同形状的布尔类型张量  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 2, 3],\n         [1, 8, 4],\n         [0, 3, 6]]),\n tensor([0, 2, 3, 1, 4, 0, 3]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randint(0, 9, size=(3, 3))\n",
    "mask = t.le(5)\n",
    "t_select = torch.masked_select(t,mask)\n",
    "t, t_select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.reshape()\n",
    "功能：变换张量形状  \n",
    "注意事项：当张量在内存中是连续的，新张量与input共享数据内存  \n",
    "* input:要变换的张量  \n",
    "* shape:新张量的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0, 1, 6],\n        [3, 4, 7, 5]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randperm(8)\n",
    "t_reshape = torch.reshape(t, (2, 4))\n",
    "t_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.transpose()  \n",
    "功能：交换张量的两个维度  \n",
    "* input:要变换的张量  \n",
    "* dim0:要交换的维度  \n",
    "* dim1:要交换的维度  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((2,3,4))\n",
    "t_transpose = torch.transpose(t,0,1)\n",
    "t_transpose.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.t()  \n",
    "功能：2维张量转置，对矩阵而言，等价于torch.transpose(input,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((2,3))\n",
    "tt = torch.t(t)\n",
    "tt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.squeeze()  \n",
    "功能：压缩长度为1的维度(轴)  \n",
    "* dim:若为None，移除所有长度为1的轴；若指定维度，当且仅当该轴长度为1时，可以被移除；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((1,2,3,1))\n",
    "t_squeeze = torch.squeeze(t)\n",
    "t_squeeze.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.unsqueeze()  \n",
    "功能：依据dim扩展维度  \n",
    "* dim:扩展的维度  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((1,2,3))\n",
    "t_unsqueeze = torch.unsqueeze(t,0)\n",
    "t_unsqueeze.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量数学运算  \n",
    "加减乘除  \n",
    "对数，指数，幂函数  \n",
    "三角函数  \n",
    "torch.add()  \n",
    "功能：逐元素计算input+alpha*other  \n",
    "* input:第一个张量  \n",
    "* alpha:乘项因子  \n",
    "* other:第二个张量  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5124, -0.2997,  0.6655],\n         [ 0.2734,  2.0731, -1.9578],\n         [ 2.8238,  0.2384, -0.6317]]),\n tensor([[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]]),\n tensor([[ 9.4876,  9.7003, 10.6655],\n         [10.2734, 12.0731,  8.0422],\n         [12.8238, 10.2384,  9.3683]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_0 = torch.randn((3,3))\n",
    "t_1 = torch.ones_like(t_0)\n",
    "t_add = torch.add(t_0, 10, t_1)\n",
    "t_0, t_1, t_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
